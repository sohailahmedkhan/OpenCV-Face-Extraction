{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Face Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can be used to extract faces from videos. The code works by getting individual frames one by one from the video and then extracts faces from the individual frames. This code extracts faces from every frame within the video, but can be changed to extract faces from different intervals. \n",
    "\n",
    "OpenCV's CNN based face detection model is used to detect faces as it is robust against large poses or faces at distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageChops, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'videos/vid_1/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get video folders in list\n",
    "# expects each video in separate folder, with folder having the same name as the video\n",
    "\n",
    "test_folders_list = sorted(glob.glob(\"videos/*/\"))\n",
    "(test_folders_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load opencv cnn face detector\n",
    "net = cv2.dnn.readNetFromCaffe('OpenCV_CNN/deploy.prototxt.txt', 'OpenCV_CNN/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "\n",
    "# parent directory to store extracted face frames\n",
    "parent_dir = \"extracted_faces/\"\n",
    "\n",
    "for i in range(len(test_folders_list)):\n",
    "    # create folders to save extracted face frames\n",
    "    path = os.path.join(parent_dir, test_folders_list[i].split('/')[-2] + '.mp4').split('.')[0]\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    count = 0\n",
    "    # get video location to extract faces\n",
    "    vid = (test_folders_list[i]) + test_folders_list[i].split('/')[-2] + '.mp4'\n",
    "    video_capture = cv2.VideoCapture(vid)\n",
    "    frameRate = video_capture.get(5)\n",
    "    while video_capture.isOpened():\n",
    "        frameId = video_capture.get(1)\n",
    "        ret, frame = video_capture.read()\n",
    "        if ret != True:\n",
    "            break\n",
    "        if frameId % ((int(frameRate+1))*1) != 0:\n",
    "            (h, w) = frame.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "#             for i, d in enumerate(face_rects):\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                if confidence > 0.5:\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    if startX is None or startY is None or endX is None or endY is None:\n",
    "                        break\n",
    "                    else:\n",
    "                        try:\n",
    "                            # extract first 10 frames from the video \n",
    "                            if count<10:\n",
    "                                # save frames, image size = 299x299\n",
    "                                cv2.imwrite(str(path)+'/' + vid.split('.')[0].split('/')[-1] + \"_\" + str(count)+\".png\", cv2.resize(frame[startY-15:endY+15, startX-15:endX+15], (299,299), cv2.INTER_AREA))\n",
    "                                count+=1\n",
    "                            else:\n",
    "                                video_capture.release()\n",
    "                                break\n",
    "                        except Exception as e:\n",
    "                            break\n",
    "    video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
